{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP9103ZB4p2OiiiSsBbfARB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishallmaurya/sentiment_analyzer_backend/blob/main/predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install FastAPI pymongo emoji load_dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f5ahOrlswvm",
        "outputId": "a7f685b7-a4ff-408f-d0cc-2577af980997"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: FastAPI in /usr/local/lib/python3.11/dist-packages (0.115.11)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n",
            "Collecting load_dotenv\n",
            "  Downloading load_dotenv-0.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from FastAPI) (0.46.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from FastAPI) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from FastAPI) (4.12.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Collecting python-dotenv (from load_dotenv)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->FastAPI) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->FastAPI) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->FastAPI) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->FastAPI) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->FastAPI) (1.3.1)\n",
            "Downloading load_dotenv-0.1.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, load_dotenv\n",
            "Successfully installed load_dotenv-0.1.0 python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import numpy as np\n",
        "import emoji\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datetime import datetime\n",
        "from pymongo import MongoClient\n",
        "from text_preprocessing import cleaning_tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO67saVYsjo-",
        "outputId": "7e0453b5-79f2-42e1-82f3-7de1ed91bc6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n"
      ],
      "metadata": {
        "id": "mV3i9w_EtTMM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = pickle.load(open(\"/content/model.pkl\", \"rb\"))\n",
        "vectorizer = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "tgZU8yd-tW2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "3REUhhREt2r7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oLvtRVCUsNV6"
      },
      "outputs": [],
      "source": [
        "class TweetInput(BaseModel):\n",
        "    tweet: str\n",
        "\n",
        "def emoji_to_text(emoji_string):\n",
        "    return ' '.join(emoji.demojize(e) for e in emoji_string) if emoji_string else ''\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict_sentiment(tweet_input: TweetInput):\n",
        "  try:\n",
        "    tweet = tweet_input.tweet\n",
        "    clean_text, extracted_emojis = cleaning_tweets(tweet)\n",
        "\n",
        "    emoji_text = emoji_to_text(extracted_emojis)\n",
        "\n",
        "    text_embedding = vectorizer.encode([clean_text], convert_to_numpy=True)\n",
        "    embedding_dim = vectorizer.get_sentence_embedding_dimension()\n",
        "\n",
        "    emoji_embedding = [\n",
        "        vectorizer.encode(emoji_text, convert_to_numpy=True)\n",
        "        if emoji_text.strip()\n",
        "        else np.zeros(embedding_dim)\n",
        "    ]\n",
        "\n",
        "    text_features = np.hstack((text_embedding, emoji_embedding))\n",
        "\n",
        "    sentiment_class = clf.predict(text_features)[0]\n",
        "\n",
        "    return {\"tweet\": tweet, \"predicted_class\": sentiment_class}\n",
        "  except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing request: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4H-lQ8gp1wyO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}